{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f645a4ca-1962-4a78-914a-64fefaf2cc90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tespit edilen parçalar: ['all_merged_data.csv']\n",
      "all_merged_data.csv işleniyor...\n",
      "İşlem tamamlandı! 28072 adet nokta ve tüm sütunlar 'tum_konteyner_lokasyonlari_detayli.csv' dosyasına kaydedildi.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import io\n",
    "import glob\n",
    "\n",
    "# 1. AYARLAR: Süreyi saniyeye çeviren fonksiyon\n",
    "def hms_to_sec(t):\n",
    "    t = str(t).strip()\n",
    "    if not t or t == 'nan': return 0\n",
    "    days = 0\n",
    "    if 'g' in t: \n",
    "        parts = t.split('g')\n",
    "        try:\n",
    "            days = int(parts[0].strip())\n",
    "            t = parts[1].strip()\n",
    "        except: pass\n",
    "    parts = t.split(':')\n",
    "    try:\n",
    "        if len(parts) == 3:\n",
    "            return days*86400 + int(parts[0])*3600 + int(parts[1])*60 + int(parts[2])\n",
    "        elif len(parts) == 2:\n",
    "            return days*86400 + int(parts[0])*60 + int(parts[1])\n",
    "    except: return 0\n",
    "    return 0\n",
    "\n",
    "# 2. DOSYALARI BUL VE TEMİZLEYEREK BİRLEŞTİR\n",
    "dosyalar = sorted(glob.glob(\"all_merged_data*.csv\"))\n",
    "print(f\"Tespit edilen parçalar: {dosyalar}\")\n",
    "\n",
    "sutun_isimleri = ['#', 'vehicle_id', 'Enlem', 'Boylam', 'Duraklama Süresi', 'Rölanti Süresi', \n",
    "                  'Yükseklik', 'Durum', 'Açıklama', 'Tarih', 'Saat', 'Gun', \n",
    "                  'Hız(km/sa)', 'Mesafe(km)', 'Mesafe Sayacı(km)', 'Adres', 'Mahalle', 'Kaynak']\n",
    "\n",
    "parca_listesi = []\n",
    "\n",
    "for dosya in dosyalar:\n",
    "    print(f\"{dosya} işleniyor...\")\n",
    "    temiz_satirlar = []\n",
    "    with open(dosya, 'r', encoding='utf-8-sig') as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if line.startswith('\"') and line.endswith('\"'):\n",
    "                line = line[1:-1]\n",
    "            line = line.replace('\"\"', '\"')\n",
    "            \n",
    "            if line.startswith('#') or not line or 'vehicle_id' in line:\n",
    "                continue\n",
    "            temiz_satirlar.append(line)\n",
    "    \n",
    "    df_parca = pd.read_csv(io.StringIO(\"\\n\".join(temiz_satirlar)), header=None, names=sutun_isimleri)\n",
    "    parca_listesi.append(df_parca)\n",
    "\n",
    "df = pd.concat(parca_listesi, ignore_index=True)\n",
    "\n",
    "# 3. KONTEYNIR NOKTALARINI FİLTRELE\n",
    "df['Saniye'] = df['Duraklama Süresi'].apply(hms_to_sec)\n",
    "\n",
    "# Kriter: 30 saniye ile 10 dakika arası duraklamalar\n",
    "konteyner_filtresi = df[(df['Saniye'] >= 30) & (df['Saniye'] <= 600)].copy()\n",
    "\n",
    "# Tekilleştirme için geçici yuvarlama kolonları\n",
    "konteyner_filtresi['Lat_rnd'] = konteyner_filtresi['Enlem'].round(4)\n",
    "konteyner_filtresi['Lon_rnd'] = konteyner_filtresi['Boylam'].round(4)\n",
    "\n",
    "# Mükerrerleri temizle (6621 benzersiz nokta kalacak)\n",
    "son_liste = konteyner_filtresi.drop_duplicates(subset=['Lat_rnd', 'Lon_rnd']).copy()\n",
    "\n",
    "# 4. TEMİZLİK VE KAYDETME\n",
    "# Analiz için kullandığımız geçici kolonları siliyoruz ki dosya orijinal formatta kalsın\n",
    "son_liste = son_liste.drop(columns=['Saniye', 'Lat_rnd', 'Lon_rnd'])\n",
    "\n",
    "cikti_dosyasi = 'tum_konteyner_lokasyonlari_detayli.csv'\n",
    "# Seçim yapmadan TÜM kolonları kaydediyoruz\n",
    "son_liste.to_csv(cikti_dosyasi, index=False, encoding='utf-8-sig')\n",
    "\n",
    "print(f\"İşlem tamamlandı! {len(son_liste)} adet nokta ve tüm sütunlar '{cikti_dosyasi}' dosyasına kaydedildi.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dcbfedb9-228c-4376-a48d-16c9739e3990",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "İşlem başarıyla tamamlandı!\n",
      "Yeni dosya 'konteyner_lokasyonlari_tipli.csv' adıyla kaydedildi.\n",
      "Toplam sütun sayısı: 19\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 1. Dosyaları yükle\n",
    "# tum_konteyner_lokasyonlari_detayli.csv dosyanızın klasörde olduğundan emin olun\n",
    "konteyner_df = pd.read_csv('tum_konteyner_lokasyonlari_detayli.csv')\n",
    "fleet_df = pd.read_csv('fleet.csv')\n",
    "\n",
    "# 2. Fleet dosyasından sadece eşleştirme için gereken sütunları alalım\n",
    "# vehicle_id üzerinden giderek yanına vehicle_type sütununu ekleyeceğiz\n",
    "fleet_mapping = fleet_df[['vehicle_id', 'vehicle_type']].drop_duplicates()\n",
    "\n",
    "# 3. Sol Birleştirme (Left Merge) işlemi\n",
    "# Bu işlem ana dosyanızdaki tüm satırları korur ve her vehicle_id'nin yanına karşılık gelen tipi yazar\n",
    "son_df = pd.merge(konteyner_df, fleet_mapping, on='vehicle_id', how='left')\n",
    "\n",
    "# 4. Tüm kolonların olduğu yeni dosyayı kaydet\n",
    "son_df.to_csv('konteyner_lokasyonlari_tipli.csv', index=False, encoding='utf-8-sig')\n",
    "\n",
    "print(f\"İşlem başarıyla tamamlandı!\")\n",
    "print(f\"Yeni dosya 'konteyner_lokasyonlari_tipli.csv' adıyla kaydedildi.\")\n",
    "print(f\"Toplam sütun sayısı: {len(son_df.columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9083d5c-95eb-4793-9638-dfbdeb623c80",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (base)",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
